{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Recurrent Neural Netowrks(RNN)\n",
        "\n",
        "RNN is a type of artificial neural network, which uses sequential data or time series data-> RNN remembers the previous data inputs and the relation among different contexts.\n",
        "\n",
        "RNN-> a neural network where the output is fed as input to the current step-> Speech Recognition\n",
        "\n",
        "In traditional neural networks, all the inputs and outputs are independent of each other, but in case when it is required to predict the next word of a sentence, the previous words are required and hence there is a need to remember the previous words. Thus RNN came into existence, which solved this issue with the help of a hidden layer.\n",
        "\n",
        "RNN have a memory that stores all information about the calculations. It employs the same settings for each input since it produces the same outcome by performing the same task on all the input layers.\n",
        "\n"
      ],
      "metadata": {
        "id": "EBGZS3vVwZr8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bR-u9LgBvxP7"
      },
      "outputs": [],
      "source": [
        "#import the packages\n",
        "#'imdb' is movie review dataset, labeled by sentiment-> +ve and -ve\n",
        "#'word embedding' in NLP is a technique where individual words are represented as real-valued vectors in a lower-dimensional space and\n",
        "#captures inter-words semantics. Each words is represented by a real-valued vector-> same as vectorizers, but for text data\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, SimpleRNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the maximum number of words to use in the vocabulary\n",
        "max_features = 10000\n",
        "# Load the IMDb dataset\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vt8flX2l6wA",
        "outputId": "9c92bcaa-3598-439c-fb86-a8796f9e8ef4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = 100\n",
        "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "#'max_len'-> tells how many sentences to be read and stored in the array\n",
        "#'pad_sequence'-> transforms a list (of length num_samples ) of sequences (lists of integers) into a 2D Numpy array of shape (num_samples, num_timesteps)\n",
        "#'pad_sequence'-> samples are each words, time_stamps are the relating the words in each sentence sequence"
      ],
      "metadata": {
        "id": "iAaX6vjgl_cN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_pz6wVnmJMf",
        "outputId": "2ba5e646-1b25-4cbb-b125-2ea0b9d983cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1415,   33,    6, ...,   19,  178,   32],\n",
              "       [ 163,   11, 3215, ...,   16,  145,   95],\n",
              "       [1301,    4, 1873, ...,    7,  129,  113],\n",
              "       ...,\n",
              "       [  11,    6, 4065, ...,    4, 3586,    2],\n",
              "       [ 100, 2198,    8, ...,   12,    9,   23],\n",
              "       [  78, 1099,   17, ...,  204,  131,    9]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the RNN model\n",
        "model = Sequential()\n",
        "#the model is in layers\n",
        "\n",
        "model.add(Embedding(input_dim=max_features, output_dim=32, input_length=maxlen))\n",
        "#'embedding' is used to convert text data into numerics, the input and output dimensions are defined at the same time\n",
        "#each epoch 'time_stamps' is the output dimension\n",
        "\n",
        "model.add(SimpleRNN(units=32))\n",
        "#the 'unit' tells the 'time_stamps' relations, how many iterations to be got\n",
        "\n",
        "model.add(Dense(units=1, activation='sigmoid'))\n",
        "#just before the output layer, there will be 32 ouputs and in the last layer, we will get 1 output only"
      ],
      "metadata": {
        "id": "fOVmXpG_mW09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "L_nG6wammjpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=10, batch_size=128, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrJhd4sQmoXq",
        "outputId": "4d702c65-d640-4548-cf50-276177a66a1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "196/196 [==============================] - 54s 242ms/step - loss: 0.5859 - accuracy: 0.6751 - val_loss: 0.4615 - val_accuracy: 0.7855\n",
            "Epoch 2/10\n",
            "196/196 [==============================] - 32s 161ms/step - loss: 0.3748 - accuracy: 0.8386 - val_loss: 0.3717 - val_accuracy: 0.8379\n",
            "Epoch 3/10\n",
            "196/196 [==============================] - 30s 152ms/step - loss: 0.2989 - accuracy: 0.8789 - val_loss: 0.3820 - val_accuracy: 0.8368\n",
            "Epoch 4/10\n",
            "196/196 [==============================] - 27s 138ms/step - loss: 0.2497 - accuracy: 0.9030 - val_loss: 0.4377 - val_accuracy: 0.7929\n",
            "Epoch 5/10\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.1942 - accuracy: 0.9281 - val_loss: 0.4528 - val_accuracy: 0.7960\n",
            "Epoch 6/10\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.1362 - accuracy: 0.9531 - val_loss: 0.4856 - val_accuracy: 0.7959\n",
            "Epoch 7/10\n",
            "196/196 [==============================] - 27s 139ms/step - loss: 0.0855 - accuracy: 0.9724 - val_loss: 0.5404 - val_accuracy: 0.8183\n",
            "Epoch 8/10\n",
            "196/196 [==============================] - 26s 135ms/step - loss: 0.0530 - accuracy: 0.9843 - val_loss: 0.6977 - val_accuracy: 0.7572\n",
            "Epoch 9/10\n",
            "196/196 [==============================] - 25s 128ms/step - loss: 0.0315 - accuracy: 0.9911 - val_loss: 0.6884 - val_accuracy: 0.8226\n",
            "Epoch 10/10\n",
            "196/196 [==============================] - 26s 134ms/step - loss: 0.0223 - accuracy: 0.9939 - val_loss: 0.7289 - val_accuracy: 0.8204\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e2d5aee30>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('rnn1.h5')\n",
        "\n",
        "#save the model for"
      ],
      "metadata": {
        "id": "6-54bEWGmr8w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJLyHcmloDyK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}